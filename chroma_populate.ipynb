{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain beautifulsoup4 chromadb youtube-transcript-api unstructured praw tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import praw\n",
    "\n",
    "from langchain.document_loaders import (\n",
    "    YoutubeLoader,\n",
    "    UnstructuredURLLoader\n",
    ")\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    }
   ],
   "source": [
    "# Define text chunk strategy\n",
    "splitter = CharacterTextSplitter(\n",
    "  chunk_size=2000, \n",
    "  chunk_overlap=50,\n",
    "  separator=\" \"\n",
    ")\n",
    "\n",
    "youtube_videos = [\n",
    "    \"DKuGhNl2ACw\",\n",
    "    \"oePpR0W-tXQ\",\n",
    "    \"RemlqHZiWlw\",\n",
    "    \"tVVYpD4joB0\",\n",
    "    \"OzfKAT2PZk4\",\n",
    "    \"VJfMi9szpBg\",\n",
    "    \"ivWC5WncvsM\",\n",
    "    \"LjZlAzr8MuQ\",\n",
    "    \"-R0LvgywiWk\",\n",
    "    \"tSCuRXnfLuI\",\n",
    "    \"uj8hjAjI7p4\",\n",
    "    \"gqK3dCpwzxE\",\n",
    "    \"b18OH-7A1zo\",\n",
    "    \"8dHyDCb8-vE\",\n",
    "    \"lwXSR4-nq2U\"\n",
    "]\n",
    "\n",
    "yt_data_split = []\n",
    "# Youtube\n",
    "for youtube_video in youtube_videos:\n",
    "  yt_loader = YoutubeLoader(youtube_video)\n",
    "  yt_data = yt_loader.load()\n",
    "  yt_data_split += splitter.split_documents(yt_data)\n",
    "print(len(yt_data_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "website_urls = [\n",
    "    \"https://www.crxsi.com/repair/timing.belt/\",\n",
    "    \"https://www.crxcommunity.com/threads/how-to-replace-the-timing-belt-and-waterpump.500/\",\n",
    "    \"https://www.hondapartsonline.net/blog/how-to-change-the-spark-plugs-in-your-honda-civic\",\n",
    "    \"https://www.crxcommunity.com/threads/how-to-remove-the-transmission-manual.51949/\",\n",
    "    \"https://www.crxcommunity.com/threads/how-to-replace-the-clutch-and-flywheel.227/\",\n",
    "    \"https://www.crxcommunity.com/threads/how-to-check-your-ignition-timing.16915/\",\n",
    "    \"https://www.crxcommunity.com/threads/obd0-ecu-codes-and-more.9903/\"\n",
    "]\n",
    "website_loader = UnstructuredURLLoader(urls=website_urls)\n",
    "website_data = website_loader.load()\n",
    "website_data_split = splitter.split_documents(website_data)\n",
    "print(len(website_data_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1294\n"
     ]
    }
   ],
   "source": [
    "# Stackexchange\n",
    "so_data = []\n",
    "for i in range(1, 20):\n",
    "    # Define the Stack Exchange API endpoint and parameters\n",
    "    api_url = \"https://api.stackexchange.com/2.3/questions\"\n",
    "    params = {\n",
    "        \"order\": \"desc\",\n",
    "        \"sort\": \"votes\",\n",
    "        \"filter\": \"!-MBrU_IzpJ5H-AG6Bbzy.X-BYQe(2v-.J\",\n",
    "        \"site\": \"mechanics\",\n",
    "        \"pagesize\": 100,\n",
    "        \"page\": i,\n",
    "    }\n",
    "    # Send GET request to Stack Exchange API\n",
    "    response = requests.get(api_url, params=params)\n",
    "    data = response.json()\n",
    "    # Retrieve the resolved questions\n",
    "    resolved_questions = [\n",
    "        question\n",
    "        for question in data[\"items\"]\n",
    "        if question[\"is_answered\"] and question.get(\"accepted_answer_id\")\n",
    "    ]\n",
    "\n",
    "    # Print the resolved questions\n",
    "    for question in resolved_questions:\n",
    "        text = (\n",
    "            \"Title:\",\n",
    "            question[\"title\"] + \"\\n\" + \"Question:\",\n",
    "            BeautifulSoup(question[\"body\"]).get_text()\n",
    "            + \"\\n\"\n",
    "            + BeautifulSoup(\n",
    "                [x[\"body\"] for x in question[\"answers\"] if x[\"is_accepted\"]][0]\n",
    "            ).get_text(),\n",
    "        )\n",
    "        source = question[\"link\"]\n",
    "        so_data.append(Document(page_content=str(text), metadata={\"source\": source}))\n",
    "print(len(so_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   0%|                                                                          | 0/146 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████████████████████████████████████████████████████████| 146/146 [1:18:55<00:00, 32.44s/it]\n"
     ]
    }
   ],
   "source": [
    "# Define embedding model\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model = \"llama2\",\n",
    "    num_thread = 4,\n",
    "    num_gpu = 1\n",
    ")\n",
    "\n",
    "content_data = website_data_split + yt_data_split + so_data\n",
    "content_num = len(content_data)\n",
    "\n",
    "# Create the Chroma vector store in batches\n",
    "batch_size = 10\n",
    "batches = [content_data[i:i + batch_size] for i in range(0, content_num, batch_size)]\n",
    "for batch in tqdm(batches, desc=\"Processing batches\"):\n",
    "    db = Chroma.from_documents(\n",
    "        batch, embeddings, persist_directory=\"./chroma_db\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
